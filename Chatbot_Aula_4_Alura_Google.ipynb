{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelAndrade55/Aula_4_Alura/blob/main/Chatbot_Aula_4_Alura_Google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAwX6pE6-O_J"
      },
      "source": [
        "Instalando o SDK do Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qY74I0Rg4ycL"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEdNSz70-ryM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qOWOdH5J-kNj"
      },
      "outputs": [],
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('SECRET_KEY')\n",
        "\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ocO5uM-4HK"
      },
      "source": [
        "Listar os modelos disponíveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "2jAxFWqS-7Uz",
        "outputId": "f8cbedc2-9381-4543-8a7e-721c70dd977d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YUv6oE0QBoMf"
      },
      "outputs": [],
      "source": [
        "generation_config = {\n",
        "    'candidate_count': 1,\n",
        "    'temperature': 0.5,\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wEfufMcqCGy8"
      },
      "outputs": [],
      "source": [
        "safety_settings = {\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'SEXUAL': 'BLOCK_NONE',\n",
        "    'DANGEROUS': 'BLOCK_NONE',\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxBLSZSBDIqP"
      },
      "source": [
        "Inicializando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NWjWoQUmDLfd"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name='gemini-1.0-pro',\n",
        "                               generation_config=generation_config,\n",
        "                               safety_settings=safety_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "2hCqXPFpOUiW",
        "outputId": "019a74b8-85b3-4032-9031-609276cbfdc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Introdução à IA**\n",
            "\n",
            "* O que é Inteligência Artificial (IA)?\n",
            "* Tipos de IA: Fraca, Forte, Geral\n",
            "* Aplicações da IA em vários setores\n",
            "\n",
            "**Aprendizado de Máquina (ML)**\n",
            "\n",
            "* Conceitos básicos de ML\n",
            "* Tipos de ML: Supervisionado, Não Supervisionado, Reforço\n",
            "* Algoritmos de ML comuns: Regressão, Classificação, Agrupamento\n",
            "\n",
            "**Aprendizado Profundo (DL)**\n",
            "\n",
            "* Redes Neurais e Aprendizado Profundo\n",
            "* Arquiteturas de DL: Redes Neurais Convolucionais (CNNs), Redes Neurais Recorrentes (RNNs)\n",
            "* Aplicações de DL: Reconhecimento de Imagem, Processamento de Linguagem Natural (PNL)\n",
            "\n",
            "**Visão Computacional**\n",
            "\n",
            "* Reconhecimento de Padrões e Processamento de Imagem\n",
            "* Deteção de Objetos, Segmentação de Imagem\n",
            "* Aplicações em visão de máquinas e veículos autônomos\n",
            "\n",
            "**Processamento de Linguagem Natural (PNL)**\n",
            "\n",
            "* Compreensão e Geração de Linguagem\n",
            "* Análise de Sentimento, Resumo de Texto\n",
            "* Aplicações em chatbots e assistentes virtuais\n",
            "\n",
            "**IA Responsável**\n",
            "\n",
            "* Ética e Implicações Sociais da IA\n",
            "* Viés e Discriminação em Sistemas de IA\n",
            "* Regulamentações e Diretrizes para o Desenvolvimento e Uso de IA\n",
            "\n",
            "**Ferramentas e Bibliotecas**\n",
            "\n",
            "* Linguagens de programação para IA: Python, R\n",
            "* Bibliotecas de IA: TensorFlow, PyTorch, Keras\n",
            "* Ferramentas de desenvolvimento de IA: Jupyter Notebook, Google Colab\n",
            "\n",
            "**Recursos Adicionais**\n",
            "\n",
            "* Cursos Online: Coursera, edX, Udemy\n",
            "* Livros e Artigos: \"Inteligência Artificial: Uma Abordagem Moderna\", \"Aprendizado de Máquina com Python\"\n",
            "* Comunidades e Fóruns: Kaggle, Stack Overflow\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(\"Vamos aprender conteúdo sobre IA. Me dê sugestões.\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttri9lMgO0nZ"
      },
      "source": [
        "Criando o Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_cwEtoYyO3cK"
      },
      "outputs": [],
      "source": [
        "chat = model.start_chat(history=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "rEKqiMhJPNtk",
        "outputId": "dc484216-4027-456a-d587-98039eed4edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: FIM\n",
            "Resposta:  **FIM**\n",
            "\n",
            "**Full Information Maximum Likelihood (FIML)**\n",
            "\n",
            "**Definition:**\n",
            "\n",
            "FIML is a statistical estimation method used in structural equation modeling (SEM) to estimate model parameters when missing data is present.\n",
            "\n",
            "**Key Features:**\n",
            "\n",
            "* **Full information:** Uses all available data, including missing values.\n",
            "* **Maximum likelihood:** Estimates parameters that maximize the likelihood of observing the data.\n",
            "* **Iterative:** Involves multiple rounds of estimation until a convergence criterion is met.\n",
            "\n",
            "**Advantages:**\n",
            "\n",
            "* Provides unbiased estimates even when missing data is present.\n",
            "* Can handle complex missing data patterns, such as missing at random (MAR) and missing not at random (MNAR).\n",
            "* Allows for the estimation of models with latent variables.\n",
            "\n",
            "**Disadvantages:**\n",
            "\n",
            "* Computationally intensive, especially for large datasets.\n",
            "* May not converge in some cases, particularly with complex models and large amounts of missing data.\n",
            "* Requires assumptions about the missing data mechanism, which may not always be met.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "FIML is commonly used in SEM to:\n",
            "\n",
            "* Estimate models with missing data.\n",
            "* Test hypotheses about model parameters.\n",
            "* Conduct sensitivity analyses to assess the impact of missing data on model results.\n",
            "\n",
            "**Example:**\n",
            "\n",
            "Consider a SEM model with two observed variables, X and Y, and a latent variable, Z. If some data points for X and Y are missing, FIML can be used to estimate the model parameters based on the available data.\n",
            "\n",
            "**Alternatives to FIML:**\n",
            "\n",
            "* **Multiple Imputation:** Estimates missing values multiple times and combines the results.\n",
            "* **Expectation-Maximization (EM) Algorithm:** Iterates between estimating missing values and updating model parameters.\n",
            "* **Weighted Least Squares (WLS) Estimation:** Uses weights to adjust for missing data. \n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ],
      "source": [
        "prompt = input(\"Esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta: \", response.text, \"\\n\")\n",
        "  prompt = input(\"Esperando prompt: \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mQbfUzpBqQF",
        "outputId": "1d70fed1-31e7-4cb9-9e24-f63e7a891990"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatSession(\n",
              "    model=genai.GenerativeModel(\n",
              "        model_name='models/gemini-1.0-pro',\n",
              "        generation_config={'candidate_count': 1, 'temperature': 0.5},\n",
              "        safety_settings={<HarmCategory.HARM_CATEGORY_HARASSMENT: 7>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_HATE_SPEECH: 8>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: 9>: <HarmBlockThreshold.BLOCK_NONE: 4>, <HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: 10>: <HarmBlockThreshold.BLOCK_NONE: 4>},\n",
              "        tools=None,\n",
              "        system_instruction=None,\n",
              "    ),\n",
              "    history=[glm.Content({'parts': [{'text': 'FIM'}], 'role': 'user'}), glm.Content({'parts': [{'text': '**FIM**\\n\\n*...missing data.'}], 'role': 'model'})]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifica a lista de histórico do chat"
      ],
      "metadata": {
        "id": "EPZlEis7By1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkguWHr1Bv2m",
        "outputId": "8b335bad-b052-4a9b-f9a1-840a4e8408d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"FIM\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"**FIM**\\n\\n**Full Information Maximum Likelihood (FIML)**\\n\\n**Definition:**\\n\\nFIML is a statistical estimation method used in structural equation modeling (SEM) to estimate model parameters when missing data is present.\\n\\n**Key Features:**\\n\\n* **Full information:** Uses all available data, including missing values.\\n* **Maximum likelihood:** Estimates parameters that maximize the likelihood of observing the data.\\n* **Iterative:** Involves multiple rounds of estimation until a convergence criterion is met.\\n\\n**Advantages:**\\n\\n* Provides unbiased estimates even when missing data is present.\\n* Can handle complex missing data patterns, such as missing at random (MAR) and missing not at random (MNAR).\\n* Allows for the estimation of models with latent variables.\\n\\n**Disadvantages:**\\n\\n* Computationally intensive, especially for large datasets.\\n* May not converge in some cases, particularly with complex models and large amounts of missing data.\\n* Requires assumptions about the missing data mechanism, which may not always be met.\\n\\n**Applications:**\\n\\nFIML is commonly used in SEM to:\\n\\n* Estimate models with missing data.\\n* Test hypotheses about model parameters.\\n* Conduct sensitivity analyses to assess the impact of missing data on model results.\\n\\n**Example:**\\n\\nConsider a SEM model with two observed variables, X and Y, and a latent variable, Z. If some data points for X and Y are missing, FIML can be used to estimate the model parameters based on the available data.\\n\\n**Alternatives to FIML:**\\n\\n* **Multiple Imputation:** Estimates missing values multiple times and combines the results.\\n* **Expectation-Maximization (EM) Algorithm:** Iterates between estimating missing values and updating model parameters.\\n* **Weighted Least Squares (WLS) Estimation:** Uses weights to adjust for missing data.\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melhorar a vizualização"
      ],
      "metadata": {
        "id": "eeYHNTEGB-zA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rKV3cprSCAag"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBZBu4UGhO8xoFZEnNn+lM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}